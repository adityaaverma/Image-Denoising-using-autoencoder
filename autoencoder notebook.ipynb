{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30207,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Denoising with Autoencoders\n\n## Task 1: Introduction and Importing Libraries\n___","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nfrom tensorflow.keras.datasets import mnist\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\nfrom tensorflow.keras.utils import to_categorical\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:19.406035Z","iopub.execute_input":"2022-07-20T17:54:19.407199Z","iopub.status.idle":"2022-07-20T17:54:22.004558Z","shell.execute_reply.started":"2022-07-20T17:54:19.407129Z","shell.execute_reply":"2022-07-20T17:54:22.003081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this project, we're using the popular __MNIST__ data set.\nThis dataset has 60,000 examples of images of handwritten\ndigits in the training set and 10,000 examples in the test\nset. The examples are black and white images of 28 by 28 as\nin 28 rows and 28 columns for each example.\nThe labels are simply digits corresponding to the 10 classes\nfrom 0 to 9.","metadata":{}},{"cell_type":"markdown","source":"## Task 2: Data Preprocessing\n___\n","metadata":{}},{"cell_type":"markdown","source":"Now we will create two neural network models in this project.\nOne will be trained to perform classification\nof these handwritten digits from the MNIST dataset\nand another model will be used to de-noise input data.\nAnd this is our auto encoder.\n\n\nEventually, we will connect the two models together and have\nthem work in conjunction as a single composite model.\nIn order to input the examples to our models, we will do\na little bit of pre-processing on them.\n\nBasically, we will normalize the values to a range of 0 to 1.\nThen, we will reshape the training and tested examples\nto 784 dimensional vectors.","metadata":{}},{"cell_type":"code","source":"# let's load the data and populate these training and test sets.\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n#These will be our numpy arrays.\n\n# Let's normalize the values\n\n# Currently the values are from 0 to 255. They're all integer values for the intensity of our pixels.\n# We can change those values and normalize the data by doing the code below.\n# We will convert the type of our X_train from integer to a floating point number.\n# And then we will divide the result by 255. \n# Now, 255 is the maximum pixel value that we have.\n# So this will convert our values and X_train for all\n# the pixels to a range of 0 to 1.\nX_train = X_train.astype('float') / 255.\n\n# Now we will do the same thing for our test set.\nX_test = X_test.astype('float') / 255.\n\n# Re-shape the examples\n# We will also reshape our examples from the shape of 28 by 28 to vectors of 784 dimensions.\n# And this will make it easy for us to input our examples into the classifier neural network that we'll create.\n# We are using the numpy's reshape; and we have 60,000 examples; and the total number of pixels we have are 784.\n# This is 28(rows) multiplied by 28(columns).\nX_train = np.reshape(X_train, (60000, 784))\n\n# Let's do the same thing for our test set examples.\nX_test = np.reshape(X_test, (10000, 784))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:22.011066Z","iopub.execute_input":"2022-07-20T17:54:22.011405Z","iopub.status.idle":"2022-07-20T17:54:22.562164Z","shell.execute_reply.started":"2022-07-20T17:54:22.011375Z","shell.execute_reply":"2022-07-20T17:54:22.560969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! Our examples are now ready to be fed into our model. The examples in the MNIST dataset are not noisy, though we\nwill take a look at some of these images in the task below.\n\nBut for our autoencoder, we do want noisy data so that we\ncan showcase the de-noising example with this method.","metadata":{}},{"cell_type":"markdown","source":"## Task 3: Adding Noise\n___\n","metadata":{}},{"cell_type":"markdown","source":"In this task, we are artificially adding some noise to our training and test set examples.\n\nLet's create a different variable for this so we can distinguish it from the original data.","metadata":{}},{"cell_type":"code","source":"# The code below will give us a uniform value between zero and one. \n# We can give it a shape of 60,000 by 784 which is the shape of our X_train.\n# Each value here in X_train will have something randomly added to them, \n# and we can scale this down a little bit by multiplying it by 0.9.\nX_train_noisy = X_train + np.random.rand(60000, 784) * 0.9\n\n# We can do the same thing for our X_test data\nX_test_noisy = X_test + np.random.rand(10000, 784) * 0.9\n\n# ensure that our values remain within the zero and one range that we normally see\n# in the previous task.\nX_train_noisy = np.clip(X_train_noisy, 0., 1.)\n\n# do the same thing for X_test_noisy\nX_test_noisy = np.clip(X_test_noisy, 0., 1.)\n\n# Note: \"0.\" and \"1.\" simply means that these are going to be floating point values.","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:22.563624Z","iopub.execute_input":"2022-07-20T17:54:22.563958Z","iopub.status.idle":"2022-07-20T17:54:23.533275Z","shell.execute_reply.started":"2022-07-20T17:54:22.563928Z","shell.execute_reply":"2022-07-20T17:54:23.532314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's great! So we added some noise to our data, but we still don't really\nknow how our data actually looks like. And what happens when we add this noise to that?\n\nSo let's take a look.","metadata":{}},{"cell_type":"code","source":"# Create a function that will plot out the first 10 images of any dataset.\n# Our function will take a few arguments. It will take \"x\", \"p\" and \"labels\". \n# Labels will be set to false by default.\n\n# normally when we're looking at the data set, we don't want to pass any \"p\" argument in our function below.\n# The \"p\" here is going to be for prediction, but we're defining it here right now because later we would \n# want to take a look at not just the images, but also their corresponding predictions from our classifier\n# and the composite model that we'll create later.\n\ndef plot(x, p, labels=False):\n    plt.figure(figsize=(20,2))\n    for i in range(10): # refers to the first 10 images that we are plotting\n        plt.subplot(1, 10, i+1) # 1 row and 10 columns; the index for the subplot \n                                # starts from one rather than from zero. \n                                # So we're adding one here to the index.\n        plt.imshow(x[i].reshape(28, 28), # this will show the image except we will have to reshape to 28 by 28 because we flattened it in the previous task.\n                   cmap = 'binary') # \"binary\" so that we see the black and white images as they are.\n        # remove the xticks and yticks so set them to blank list\n        plt.xticks([])\n        plt.yticks([])\n        if labels: # if labels is true,\n            plt.xlabel(np.argmax(p[i])) # then we also want to label our X axis.\n            # This is where the \"p\" comes in for prediction.\n            # If we have predictions on this data set, we will pass those\n            # predictions as well. And those predictions will be displayed as \n            # the X labels of the images.\n        # Come out of the for loop to display the entire plot.\n    plt.show()\n    return\n# Great! This is our plot function.\n\n# Now let's use it to display the first few images from the X_train data set.\nplot(X_train, None) # set \"None\" for the prediction","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:23.535753Z","iopub.execute_input":"2022-07-20T17:54:23.536404Z","iopub.status.idle":"2022-07-20T17:54:24.108198Z","shell.execute_reply.started":"2022-07-20T17:54:23.53637Z","shell.execute_reply":"2022-07-20T17:54:24.106948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we see a bunch of images displayed in our notebook. Awesome!\n\n\nLet's use the plot function again. But this time we want to take a look at the noisy examples.\nRemember, we just created the X_train_noisy and X_test_noisy and again, we don't have any predictions right now so set it to __None__.","metadata":{}},{"cell_type":"code","source":"plot(X_train_noisy, None)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:24.113733Z","iopub.execute_input":"2022-07-20T17:54:24.115007Z","iopub.status.idle":"2022-07-20T17:54:24.475542Z","shell.execute_reply.started":"2022-07-20T17:54:24.114959Z","shell.execute_reply":"2022-07-20T17:54:24.474363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are our same examples, but with some noise added to\nthem, and that's actually a lot of noise added to them.\n\n\nSo it will be really interesting to check out how a\nclassifier trained on the non noisy data set would perform on\na noisy data set like this one.","metadata":{}},{"cell_type":"markdown","source":"## Task 4: Building and Training a Classifier\n___\n","metadata":{}},{"cell_type":"markdown","source":"In this task, we will create a classifier and train it to classify handwritten digit\nimages from our MNIST dataset. We will use a very straightforward neural network with just\ntwo hidden layers.","metadata":{}},{"cell_type":"code","source":"classifier = Sequential([\n    Dense(256, activation='relu', input_shape=(784,)),\n    Dense(256, activation='relu'),\n    Dense(10, activation='softmax') # softmax to get probability score from this model\n])\n\n# compile our model\nclassifier.compile(\n    optimizer = 'adam', #short for adaptive moment estimate; works kinda like the RMS prop algorithm but with momentum added to that.\n    loss = 'sparse_categorical_crossentropy', # we would have used the categorical crossentropy if our labels \n                                                # were represented in one hot encodings. But they're not. Right now, our labels are not encoded at all.\n                                                # They basically just have numeric values for the different classes. So for that reason, \n                                                # we are using sparse, categorical cross entropy\n    metrics=['accuracy']\n)\n\n# Now we can train our classifier simply by fitting the Model to X_train and y_train.\nclassifier.fit(X_train, y_train, \n               batch_size=512, # We will also set a batch_size of 512. This is normal, but this is slightly on the higher side.\n                                # And we're doing this only to speed up the training.\n               epochs=3) # And finally we will set the epochs. We will just train the model for 3 epochs.","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:24.477593Z","iopub.execute_input":"2022-07-20T17:54:24.478394Z","iopub.status.idle":"2022-07-20T17:54:28.765411Z","shell.execute_reply.started":"2022-07-20T17:54:24.478351Z","shell.execute_reply":"2022-07-20T17:54:28.764414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I should note that we are training it for just three epochs. And that's mainly because we're not really concerned\nabout the training accuracy as such. In a state of the art models, of course, you can get, like, 99.6% or something like that. With the MNIST dataset, we are not really concerned about it as long as you get something above 95%, were good.\nAnd you should get that with just three bucks.","metadata":{}},{"cell_type":"markdown","source":"Our classifier is trained with the training data set. We can check its performance on the\ntest data set.","metadata":{}},{"cell_type":"code","source":"# we'll use our classifier with evaluate function\nloss, acc = classifier.evaluate(X_test, y_test)\n\n# print out the the returned accuracy rate.\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:28.766709Z","iopub.execute_input":"2022-07-20T17:54:28.766987Z","iopub.status.idle":"2022-07-20T17:54:29.535884Z","shell.execute_reply.started":"2022-07-20T17:54:28.766962Z","shell.execute_reply":"2022-07-20T17:54:29.534467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get 97% accuracy, which is pretty good.\nAnd this is similar to what we got on the training data as\nwell. \n\n\nBut what we really wanted to see was the accuracy that we\nwould get on this classifier with the noisy test data.","metadata":{}},{"cell_type":"code","source":"# let's evaluate again but this time for our noisy data\nloss, acc = classifier.evaluate(X_test_noisy, y_test)\nprint(acc)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:29.537413Z","iopub.execute_input":"2022-07-20T17:54:29.539294Z","iopub.status.idle":"2022-07-20T17:54:30.09883Z","shell.execute_reply.started":"2022-07-20T17:54:29.53924Z","shell.execute_reply":"2022-07-20T17:54:30.097929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get something like 28%. The classifier doesn't work at all on noisy data.\nThis is pretty much random guess from the classifier.\n\nSo what we want to do now is to create an autoencoder to de-noise our noisy dataset. Then try this\nclassifiers evaluation again and see what kind of improvement our image denies.","metadata":{}},{"cell_type":"markdown","source":"In order to denoise our data, we want to create a model, the auto encoder, which takes\na noisy example as input and the original corresponding\nexample as the label.\n\nNow, if one or more hidden layers in this neural network has\na lot less nodes compared to the input and output, then\nthe training process will force the network to learn\na function similar to principal component analysis,\nessentially reducing dimensionality.\n\nAnd it will essentially force the model to learn the more important characteristics from the data set and focus only on that.","metadata":{}},{"cell_type":"markdown","source":"## Task 5: Building the Autoencoder\n___\n","metadata":{}},{"cell_type":"markdown","source":"Let's build our encoder and decoder.","metadata":{}},{"cell_type":"code","source":"# One more thing to note here is that the output layer will have a sigmoid activation.\n# We are going to use keras's functional api to create this autoencoder.\n# Let's create a variable input_image and define with the input layer from Keras, and this\n# is of shape 784 dimensional vector.\ninput_image = Input(shape=(784,))\n\n# Our encoded result is essentially going through a dense layer with reduced dimensionality.\n# Create single dense layer passing in the input_image\nencoded = Dense(64, activation='relu')(input_image)\n\n# create one also for decoding\n# Create single dense layer passing in the encoded\ndecoded = Dense(784, activation='sigmoid')(encoded)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:30.100121Z","iopub.execute_input":"2022-07-20T17:54:30.100422Z","iopub.status.idle":"2022-07-20T17:54:30.124207Z","shell.execute_reply.started":"2022-07-20T17:54:30.100395Z","shell.execute_reply":"2022-07-20T17:54:30.123318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we take something that 784 features. We reduce the dimensionality and we force it\nto a 64 node fully connected layer.\nAnd then we expand it again back to 784 values.\n\nSo with this way, hopefully, our autoencoder, when we train it,\nlearns to focus only on the important stuff and then is\nable to because of that is able to de noise and ignore\nthe data which is not important.\n\nThis is where the sigmoid activation will also come into the picture.\nThe higher linear values of the last layer will become closer\nto the maximum normalized pixel value of one. And the low linear values will converge towards the minimum normalized pixel values of zero.\nSo this stress of activation makes sense, given the examples,\nand then put our black and white images. There is still some scope for having a variety of pixel\nvalues with some linearity in it, because the sigmoid does have a linear part to it as well.\nBut most values will converge to either zero in one, and that works well for us.\n\nHowever, this does not give us the ah auto encoder model just yet.\nWe will need to use the model class from keras to create that.","metadata":{}},{"cell_type":"code","source":"# Build the Autoencoder.\n# our input is going to be input image and output is simply going to be the decoded output.\nautoencoder = Model(input_image, decoded)\n\n# We also need to compile it.\n# We'll also set the loss because we are using softmax in the final layer.\n# Use the optimizer as adam.\nautoencoder.compile(loss='binary_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:30.125711Z","iopub.execute_input":"2022-07-20T17:54:30.126391Z","iopub.status.idle":"2022-07-20T17:54:30.138667Z","shell.execute_reply.started":"2022-07-20T17:54:30.126349Z","shell.execute_reply":"2022-07-20T17:54:30.137602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have the autoencoder, we'll go to the next task and train this autoencoder.","metadata":{}},{"cell_type":"markdown","source":"## Task 6: Training the Autoencoder\n___\n","metadata":{}},{"cell_type":"markdown","source":"We will use the noisy training set examples as our examples and the original training set examples, the ones without any noise, will be used as our labels for the autoencoder to learn de-noising. \n\nThe idea being that by doing this training, our autoencoder will learn to recognize the important\nfeatures and learn to ignore the rest of the not so important features.","metadata":{}},{"cell_type":"code","source":"autoencoder.fit(\n    X_train_noisy, X_train, \n    epochs=100, # We will use a slightly higher number of epochs this time. \n                # We probably will not have to train 400 epochs because \n                # we're going to use early stopping callback. \n    batch_size=512, # We will set a batch size to 512. \n                    # This is slightly higher than usual, but this will help speed\n                    # up the training process.\n    validation_split=0.2, # Use a validation split of 20%,\n    verbose=False, # set verbose to false because we don't want to actually use any build logs. \n                   # Potentially because we're looking at 100 epochs. \n                   # So we don't want to crowd the notebook too much.\n                   # Instead, we will use a Lambda callback for a simple logging.\n    # Let us now define our callbacks; use early stopping; use monitor validation loss \n    # and set a patient of 5 epochs.\n    callbacks=[\n        EarlyStopping(monitor='val_loss', patience=5),\n    # So if the validation loss does not improve, as if it does not decrease \n    # for five epochs, then our model will stop the training.\n        # We will also use Lambda Callback passing in the \"on_epoch_end\" pertaining to the end of Epoch.\n        # We will use a lambda function; We will print out a validation loss;\n        # We will also set the ending of our print statement a blank underscore blank.\n        LambdaCallback(on_epoch_end=lambda e,l: print('{:.3f}'.format(l['val_loss']), end=' _ '))\n        # This is so that we don't print the validation loss for every epoch in new line. \n        # It sort of keeps going on and on in a single line until the training is complete.\n    ]\n)\n# When the training is complete, let's print out a statement \"Training is complete!\"\nprint(' _ ')\nprint('Training is complete!')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:54:30.139917Z","iopub.execute_input":"2022-07-20T17:54:30.140831Z","iopub.status.idle":"2022-07-20T17:55:33.82518Z","shell.execute_reply.started":"2022-07-20T17:54:30.140798Z","shell.execute_reply":"2022-07-20T17:55:33.824287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So now that the auto encoder is trained, let's put it to use.","metadata":{}},{"cell_type":"markdown","source":"## Task 7: Denoised Images\n___\n","metadata":{}},{"cell_type":"markdown","source":"In order to get our de-noised images, say for our test data, all we have to do is pass the noisy data\nthrough the autoencoder.","metadata":{}},{"cell_type":"code","source":"# Let's save it in a variable called prediction and use the autoencoders method to \n# get our outputs then we will pass the X_test_noisy data.\npredictions = autoencoder.predict(X_test_noisy)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:33.82669Z","iopub.execute_input":"2022-07-20T17:55:33.826986Z","iopub.status.idle":"2022-07-20T17:55:53.596481Z","shell.execute_reply.started":"2022-07-20T17:55:33.826959Z","shell.execute_reply":"2022-07-20T17:55:53.595368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To make a comparison, let's plot the images first.\nplot(X_test_noisy, None)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:53.599663Z","iopub.execute_input":"2022-07-20T17:55:53.599984Z","iopub.status.idle":"2022-07-20T17:55:53.926949Z","shell.execute_reply.started":"2022-07-20T17:55:53.599949Z","shell.execute_reply":"2022-07-20T17:55:53.925776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the noisy test images that were denoised.","metadata":{}},{"cell_type":"code","source":"# Let's plot also the denoised output.\nplot(predictions, None)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:53.9287Z","iopub.execute_input":"2022-07-20T17:55:53.929625Z","iopub.status.idle":"2022-07-20T17:55:54.313366Z","shell.execute_reply.started":"2022-07-20T17:55:53.929575Z","shell.execute_reply":"2022-07-20T17:55:54.311813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! We can see that it has a done a pretty descent job. Of course, there are ways to improve this performance, especially if we use convolutional neural networks and our autoencoder. But this is still pretty good.\n\nNow, while they look good, we also want to check out how they performed after denoising these images with our classifier.","metadata":{}},{"cell_type":"code","source":"loss, acc = classifier.evaluate(predictions, y_test)\nprint(acc)\n\n# Remember, we got fairly low accuracy score for the noisy dataset before, around 10%.\n# And of course, that score might be different everytime we re-run this model.\n# However, after doing the denoizing, this score should improve drastically.","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:54.315346Z","iopub.execute_input":"2022-07-20T17:55:54.316242Z","iopub.status.idle":"2022-07-20T17:55:54.867415Z","shell.execute_reply.started":"2022-07-20T17:55:54.316179Z","shell.execute_reply":"2022-07-20T17:55:54.866642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! Now we get 94% accuracy rate. Again it will be different everytime we re-run this, but it\nwill be in the ballpark.\n\nSo this is a lot of improvement from when we evaluated the noisy test set images with the classifier.\nNow we are successfully able to denoise our images to a degree where our classifier is actually able to recognize the digits and the classes in those images.\n\nAs one final step, we will now hook up our classifier and the auto encoder to create one composite model\nand basically complete our entire pipeline.","metadata":{}},{"cell_type":"markdown","source":"## Task 8: Composite Model\n___\nNote: If you are starting the notebook from this task, you can run cells from all previous tasks in the kernel by going to the top menu and then selecting Kernel > Restart and Run All\n___","metadata":{}},{"cell_type":"markdown","source":"Let's create our composite model to complete our entire\nprediction pipeline. We want a model in which we can simply\nfeed a noisy image, or it could be a non noisy image\nand the model will first denoise that and then use the denoised image and run\nit through the classifier to get the class prediction. The idea\nbeing that even if our incoming data in a production setting\nis noisy, our classifier should be able to work well\nbecause of the denoizing from the autoenoder.\n\nThis is a useful idea in a lot of production settings.\n\nSo, just like before, we will use keras functional API\nto do this.","metadata":{}},{"cell_type":"code","source":"input_image = Input(shape=(784,))\nx  =autoencoder(input_image)\ny = classifier(x)\n\n# Now we need to encapsulate this within a model. So we will use the model class \n# from Keras's functional API.\ndenoised_and_classify = Model(input_image, y)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:54.868369Z","iopub.execute_input":"2022-07-20T17:55:54.869071Z","iopub.status.idle":"2022-07-20T17:55:54.89775Z","shell.execute_reply.started":"2022-07-20T17:55:54.869042Z","shell.execute_reply":"2022-07-20T17:55:54.896614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's put it to work.  \nLet's get some predictions and let's use the noisy test set.","metadata":{}},{"cell_type":"code","source":"predictions = denoised_and_classify.predict(X_test_noisy)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:54.899303Z","iopub.execute_input":"2022-07-20T17:55:54.900029Z","iopub.status.idle":"2022-07-20T17:55:55.493282Z","shell.execute_reply.started":"2022-07-20T17:55:54.899982Z","shell.execute_reply":"2022-07-20T17:55:55.492285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's plot out the X_test image data and the predictions.\nplot(X_test_noisy, predictions, True)\n\n# And this time we want to show the labels.\n# So we set the labels to true and give predictions instead\n# of none that we've been doing so far.\n# This time we want to label the images as well.","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:55.494712Z","iopub.execute_input":"2022-07-20T17:55:55.495013Z","iopub.status.idle":"2022-07-20T17:55:56.131087Z","shell.execute_reply.started":"2022-07-20T17:55:55.494986Z","shell.execute_reply":"2022-07-20T17:55:56.129818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All right! So we can see the labelling is actually now pretty good.\nAlthough the number \"6\" is mislabeled, but other than that, everything else is correct.\n\nAnd if we want just to make sure, we can make a comparison with the original labels","metadata":{}},{"cell_type":"code","source":"# Except I am doing a one hot encoding on the y_test, so that they are in the format \n# that a plot function expect and set the prediction story labels to true.\nplot(X_test, to_categorical(y_test), True)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:55:56.133315Z","iopub.execute_input":"2022-07-20T17:55:56.134181Z","iopub.status.idle":"2022-07-20T17:55:56.544289Z","shell.execute_reply.started":"2022-07-20T17:55:56.134132Z","shell.execute_reply":"2022-07-20T17:55:56.543088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! So, apart from the number \"5\", which seems, not correctly\nidentified by our denoise and classifier model, everything\nelse is actually correct.","metadata":{}}]}